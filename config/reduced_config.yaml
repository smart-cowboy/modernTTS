# ARCHITECTURE
speech_decoder_num_layers: 1
text_encoder_num_layers: 1
speech_model_dimension: 64
text_model_dimension: 64
speech_decoder_num_heads: 1
text_encoder_num_heads: 1
text_encoder_feed_forward_dimension: 64
speech_decoder_feed_forward_dimension: 64
speech_decoder_prenet_dimension: 64
max_position_encoding: 100000
speech_postnet_conv_filters: 64
speech_postnet_conv_layers: 1
speech_postnet_kernel_size: 5
dropout_rate: 0.1

# LOSSES
stop_loss_scaling: 8

# DATA
n_samples: 200
mel_channels: 80
sr: 22050
mel_start_vec_value: -3
mel_end_vec_value: -4

# AUDIO
n_fft: 1024
f_max: 8000
f_min: 0
hop_length: 256
win_length: 1024
sampling_rate: 22050

# TRAINING
dropout_schedule:
  - [0, 0.9]
  - [30_000, 0.5]
learning_rate_schedule:
  - [0, 1.0e-4]
max_steps: 300_000
batch_size: 2
mask_prob: 0.3
debug: False
learning_rate: 1.0e-4 # for initialization

# LOGGING
val_freq: 60
image_freq: 70
weights_save_freq: 500
plot_attention_freq: 100
keep_n_weights: 5
keep_checkpoint_every_n_hours: 1
n_steps_avg_losses: [10, 20, 30, 50, 70, 110]
n_predictions: 1

# TOKENIZER
tokenizer_alphabet: "\"!,.:;?'-() abcdefghijklmnopqrstuvwxyzäüöß"